# -*- coding: utf-8 -*-
"""LEPrD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kNfI6ARpbBF29a2TF0IAtrW2prvQ3rNo
"""

# mount our Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import glob

!pip install --upgrade -q gspread
!pip install gspread-dataframe

import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
from skimage.io import imread
from skimage.filters import threshold_local
import imutils
from imutils import contours
import xml.etree.ElementTree as ET
import gspread
import pandas as pd
from google.colab import auth
from oauth2client.client import GoogleCredentials
from gspread_dataframe import get_as_dataframe, set_with_dataframe
auth.authenticate_user()
gc = gspread.authorize(GoogleCredentials.get_application_default())

sheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1vPMMHoKU2u0ILwot9src6kIZAj8jgwIbFbn0N36AKk4/edit#gid=0')

ws = sheet.worksheet('Sheet1')
plateDetails = get_as_dataframe(ws)
plateDetails.drop(plateDetails.columns[plateDetails.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)

indexCol = plateDetails['Index'].tolist()
indexCol = [indexCol for indexCol in indexCol if str(indexCol) != 'nan']
indexCol = [item + '.jpg' for item in indexCol]
print(indexCol)

plateLabels = plateDetails['Label'].tolist()
plateLabels = [plateLabels for plateLabels in plateLabels if str(plateLabels) != 'nan']
plateLabels = [str(i) for i in plateLabels]
print(plateLabels)
print(len(indexCol))
print(len(plateLabels))

labelDict = {k: v for v, k in enumerate(indexCol)}

np.random.seed(0)
randIndx = np.array(indexCol)
np.random.shuffle(randIndx)

N = randIndx.shape[0]
print(N)
trainingIndices = randIndx[:int(N*0.8)]
validIndices =  randIndx[int(N*0.8):int(N*0.9)]
testIndices =  randIndx[int(N*0.9):]
print(len(trainingIndices))
print(len(validIndices))
print(len(testIndices))

trainingSet = []
trainingLabel = []
counter = 0
maskList = []
carImage = -1
path = '/content/drive/My Drive/Colab Notebooks/APS360/Project/dataset/'
listOfLabel = 0
for image_path in trainingIndices:
  counter += 1
  carImage+=1
  print("Iteration Count:   ")
  print(counter)
  maskList.clear()
  print(image_path)
  input_path = (path + image_path)
  image = cv2.imread(input_path)
  # plt.imshow(image)
  # plt.show()
  cv2.waitKey(0)
  imageName = image_path[:-4]
  # print(imageName)
  rowEntry = plateDetails.loc[plateDetails['Index'] == imageName]
  # print(rowEntry)
  ymax = int(rowEntry['Ymax'])
  ymin = int(rowEntry['Ymin'])
  xmax = int(rowEntry['Xmax'])
  xmin = int(rowEntry['Xmin'])
  # print(ymax, ymin, xmax, xmin)
  #crop_img = image[ymin:ymax, xmin:xmax]
  # plt.imshow(crop_img)
  # plt.show()
  cv2.waitKey(0)
  # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  # gray2 = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
  # img_gray_mode = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

  # plt.imshow(image)
  # plt.show()
  # plt.imshow(image_rgb)
  # plt.show()
  # plt.imshow(gray)
  # plt.show()
  # plt.imshow(gray, cmap='gray')
  # plt.show()
  # for child in root.iter('xmin'):
  #   xmin = int(child.text)

  # for child in root.iter('xmax'):
  #   xmax = int(child.text)

  # for child in root.iter('ymin'):
  #   ymin = int(child.text)

  # for child in root.iter('ymax'):
  #   ymax = int(child.text)

  # print(xmin)
  # print(xmax)
  # print(ymin)
  # print(ymax)

  # crop_img = image[ymin:ymax, xmin:xmax]
  # plt.imshow(crop_img)
  # plt.show()
  # cv2.waitKey(0)

  # image = cv2.imread('/root/train/040603/P1010001.jpg')

  #image = cv2.imread('/root/train/040603/P6040015.jpg')
  #image = cv2.imread('/content/drive/My Drive/Colab Notebooks/APS360/Project/images/Cars1.png')
  # image = cv2.imread('/root/train/040603/P1010003.jpg')
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  gray2 = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
  img_gray_mode = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


  # plt.imshow(image)
  # plt.show()
  # plt.imshow(image_rgb)
  # plt.show()
  # plt.imshow(gray)
  # plt.show()
  # plt.imshow(gray, cmap='gray')
  # plt.show()
  # plt.imshow(gray2)
  # plt.show()
  # plt.imshow(img_gray_mode)
  # plt.show()
  #ksize was 3 before
  sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=1)
  sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=1)
  # plt.imshow(sobelx+sobely,cmap = 'gray')

  edged = cv2.Canny(gray, 170, 200)
  # plt.imshow(edged,cmap = 'gray')

  gray_noise = cv2.bilateralFilter(gray, 11, 17, 17)
  edged2 = cv2.Canny(gray_noise, 170, 200)
  # plt.imshow(edged2,cmap = 'gray')

  # mask = np.zeros(gray.shape,np.uint8) #Array filled with zeros, basically black box
  # image_masked = cv2.drawContours(mask,[screenCnt],0,255,-1,) #Draw found contour on mask and fill it white
  # image_masked = cv2.bitwise_and(image,image,mask=mask) #Bitwise and, to keep everything within contour

  # plt.imshow(image_masked)

  # # Now crop
  # (x, y) = np.where(mask == 255)
  # (topx, topy) = (np.min(x), np.min(y))
  # (bottomx, bottomy) = (np.max(x), np.max(y))
  # cropped_img = image[topx:bottomx+1, topy:bottomy+1]

  # plt.imshow(cropped_img)

  # # Now crop
  # (x, y) = np.where(mask == 255)
  # (topx, topy) = (np.min(x), np.min(y))
  # (bottomx, bottomy) = (np.max(x), np.max(y))
  # cropped = gray[topx:bottomx+1, topy:bottomy+1]

  # plt.imshow(cropped, cmap='gray')
  # extract the Value component from the HSV color space and apply adaptive thresholding
  # to reveal the characters on the license plate
  V = cv2.split(cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV))[2]
  # T = threshold_local(V, 29, offset=15, method="gaussian") #################ORIGINAL 29, CHANGED TO 99
  T = threshold_local(V, 99, offset=15, method="gaussian")
  thresh = (V > T).astype("uint8") * 255
  thresh = cv2.bitwise_not(thresh)

  # plt.imshow(thresh, cmap='gray')
  # plt.show()

  from skimage import measure
  import random
  good_contours = []
  labels = measure.label(thresh, neighbors=8, background=0)
  charCandidates = np.zeros(thresh.shape, dtype="uint8")
  ##print(len(np.unique(labels)))

  # loop over the unique components
  for label in np.unique(labels):
    # if this is the background label, ignore it
    if label == 0:
      continue

    # otherwise, construct the label mask to display only connected components for the
    # current label, then find contours in the label mask
    labelMask = np.zeros(thresh.shape, dtype="uint8")
    labelMask[labels == label] = 255
    cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
    # (cnts, _) = contours.sort_contours(cnts, method="top-to-bottom") ####ADDED#####################
    # (cnts, _) = contours.sort_contours(cnts, method="left-to-right") ####ADDED#####################
    # cnts = cnts[0] if imutils.is_cv2() else cnts[1]

    # cnts.sort(key=lambda x:get_contour_precedence(x, thresh.shape[1]))


    good_contours.append((cnts,labelMask))
    random.shuffle(good_contours)
    
    ############# PLOT #######################
  # good_contours.sort(key=lambda x:get_contour_precedence(x[0], thresh.shape[1]))

  good_contours.sort(key=lambda x:cv2.boundingRect(max(x[0], key=cv2.contourArea))[0])


  
  asciiLabels = []
  labelMaskList = []
  for cnts, labelMask in good_contours:
    # ensure at least one contour was found in the mask
    if len(cnts) > 0:
      # grab the largest contour which corresponds to the component in the mask, then
      # grab the bounding box for the contour

      # c = min(cnts, key=cv2.contourArea)
      c = max(cnts, key=cv2.contourArea)
      (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)
      # print('Counter: ', counter)

      # print("Divide", boxW/float(boxH))
      # print("KeepAspect", (boxW/float(boxH)) < 1.0)
      # print("Divide", cv2.contourArea(c)/float(boxW * boxH))
      # print("Keep Solidity", (cv2.contourArea(c)/float(boxW * boxH)) > 0.15)
      # print("Divide", boxH / float(thresh.shape[0]))
      # print("Keep Height", (boxH / float(thresh.shape[0]) > 0.4) and (boxH / float(thresh.shape[0])<0.95))

      # print("\n")
      
      

      # compute the aspect ratio, solidity, and height ratio for the component
      aspectRatio = boxW / float(boxH)
      solidity = cv2.contourArea(c) / float(boxW * boxH)
      heightRatio = boxH / float(thresh.shape[0])

      # determine if the aspect ratio, solidity, and height of the contour pass
      # the rules tests
      keepAspectRatio = aspectRatio < 1.0
      keepSolidity = solidity > 0.15
      keepHeight = heightRatio > 0.55 and heightRatio < 0.95
      # keepHeight = heightRatio > 0.4 and heightRatio < 0.95  ###ORIGINAL###

      # check to see if the component passes all the tests
      if keepAspectRatio and keepSolidity and keepHeight:
        # compute the convex hull of the contour and draw it on the character
        # candidates mask
        try:
          hull = cv2.convexHull(c)
          cv2.drawContours(charCandidates, [hull], -1, 255, -1) 
        except Exception:
          print("Issue with drawcontours. This is the image:        ")
          print(image_path)
          badImages.append(image_path)
          continue
        else:
          labelMask = labelMask[boxY:boxY+boxH, boxX:boxX+boxW]
          labelMask = cv2.copyMakeBorder(labelMask,5, 5, 5, 5, cv2.BORDER_CONSTANT, value=0)
          labelMask = cv2.resize(labelMask, (30,60))
          # plt.imshow(labelMask, cmap='gray')
          # plt.show()
          labelMaskList.append(labelMask)
          labelIndexVal = labelDict[image_path]
          labelString = plateLabels[labelIndexVal]
          if (not asciiLabels):
            for i in labelString:
              x = ord(i)
              if(x >= ord('0') and x <= ord('9')):
                temp = x-ord('0')
                asciiLabels.append(temp)
                # print(type(x-ord('0')))
                # print(x-ord('0'))
              else:
                temp = x-ord('A')+10
                asciiLabels.append(temp)
                # print(type(x-ord('A')+10))
                # print(x-ord('A')+10)
            trainingLabel.append(asciiLabels) 
  if (labelMaskList):
    trainingSet.append(labelMaskList)

        ############### FILTERED PLOT, BUT NOT WORKING ##########################
        # plt.imshow(labelMask, cmap='gray')
        # plt.show()  
  # print(keepAspectRatio)
  # print(keepSolidity)
  # print(keepHeight)

print(len(trainingLabel))
print(trainingLabel)
print(len(trainingSet))
#print(trainingSet)

validationSet = []
validationLabel = []

maskList = []
carImage = -1
path = '/content/drive/My Drive/Colab Notebooks/APS360/Project/dataset/'
counter = 0
for image_path in validIndices:
  carImage+=1
  counter+=1
  print("Iteration Count:   ")
  print(counter)
  maskList.clear()
  print(image_path)
  input_path = os.path.join(path, image_path)
  image = cv2.imread(input_path)
  # plt.imshow(image)
  # plt.show()
  cv2.waitKey(0)
  imageName = image_path[:-4]
  # print(imageName)
  rowEntry = plateDetails.loc[plateDetails['Index'] == imageName]
  # print(rowEntry)
  ymax = int(rowEntry['Ymax'])
  ymin = int(rowEntry['Ymin'])
  xmax = int(rowEntry['Xmax'])
  xmin = int(rowEntry['Xmin'])
  # print(ymax, ymin, xmax, xmin)
  crop_img = image[ymin:ymax, xmin:xmax]
  # plt.imshow(crop_img)
  # plt.show()
  cv2.waitKey(0)
  # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  # gray2 = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
  # img_gray_mode = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

  # plt.imshow(image)
  # plt.show()
  # plt.imshow(image_rgb)
  # plt.show()
  # plt.imshow(gray)
  # plt.show()
  # plt.imshow(gray, cmap='gray')
  # plt.show()
  # for child in root.iter('xmin'):
  #   xmin = int(child.text)

  # for child in root.iter('xmax'):
  #   xmax = int(child.text)

  # for child in root.iter('ymin'):
  #   ymin = int(child.text)

  # for child in root.iter('ymax'):
  #   ymax = int(child.text)

  # print(xmin)
  # print(xmax)
  # print(ymin)
  # print(ymax)

  # crop_img = image[ymin:ymax, xmin:xmax]
  # plt.imshow(crop_img)
  # plt.show()
  # cv2.waitKey(0)

  # image = cv2.imread('/root/train/040603/P1010001.jpg')

  #image = cv2.imread('/root/train/040603/P6040015.jpg')
  #image = cv2.imread('/content/drive/My Drive/Colab Notebooks/APS360/Project/images/Cars1.png')
  # image = cv2.imread('/root/train/040603/P1010003.jpg')
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  gray2 = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
  img_gray_mode = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


  # plt.imshow(image)
  # plt.show()
  # plt.imshow(image_rgb)
  # plt.show()
  # plt.imshow(gray)
  # plt.show()
  # plt.imshow(gray, cmap='gray')
  # plt.show()
  # plt.imshow(gray2)
  # plt.show()
  # plt.imshow(img_gray_mode)
  # plt.show()
  #ksize was 3 before
  sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=1)
  sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=1)
  # plt.imshow(sobelx+sobely,cmap = 'gray')

  edged = cv2.Canny(gray, 170, 200)
  # plt.imshow(edged,cmap = 'gray')

  gray_noise = cv2.bilateralFilter(gray, 11, 17, 17)
  edged2 = cv2.Canny(gray_noise, 170, 200)
  # plt.imshow(edged2,cmap = 'gray')

  # mask = np.zeros(gray.shape,np.uint8) #Array filled with zeros, basically black box
  # image_masked = cv2.drawContours(mask,[screenCnt],0,255,-1,) #Draw found contour on mask and fill it white
  # image_masked = cv2.bitwise_and(image,image,mask=mask) #Bitwise and, to keep everything within contour

  # plt.imshow(image_masked)

  # # Now crop
  # (x, y) = np.where(mask == 255)
  # (topx, topy) = (np.min(x), np.min(y))
  # (bottomx, bottomy) = (np.max(x), np.max(y))
  # cropped_img = image[topx:bottomx+1, topy:bottomy+1]

  # plt.imshow(cropped_img)

  # # Now crop
  # (x, y) = np.where(mask == 255)
  # (topx, topy) = (np.min(x), np.min(y))
  # (bottomx, bottomy) = (np.max(x), np.max(y))
  # cropped = gray[topx:bottomx+1, topy:bottomy+1]

  # plt.imshow(cropped, cmap='gray')
  # extract the Value component from the HSV color space and apply adaptive thresholding
  # to reveal the characters on the license plate
  V = cv2.split(cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV))[2]
  # T = threshold_local(V, 29, offset=15, method="gaussian") #################ORIGINAL 29, CHANGED TO 99
  T = threshold_local(V, 99, offset=15, method="gaussian")
  thresh = (V > T).astype("uint8") * 255
  thresh = cv2.bitwise_not(thresh)

  # plt.imshow(thresh, cmap='gray')
  # plt.show()

  from skimage import measure
  import random
  good_contours = []
  labels = measure.label(thresh, neighbors=8, background=0)
  charCandidates = np.zeros(thresh.shape, dtype="uint8")
  ##print(len(np.unique(labels)))

  # loop over the unique components
  for label in np.unique(labels):
    # if this is the background label, ignore it
    if label == 0:
      continue

    # otherwise, construct the label mask to display only connected components for the
    # current label, then find contours in the label mask
    labelMask = np.zeros(thresh.shape, dtype="uint8")
    labelMask[labels == label] = 255
    cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
    # (cnts, _) = contours.sort_contours(cnts, method="top-to-bottom") ####ADDED#####################
    # (cnts, _) = contours.sort_contours(cnts, method="left-to-right") ####ADDED#####################
    # cnts = cnts[0] if imutils.is_cv2() else cnts[1]

    # cnts.sort(key=lambda x:get_contour_precedence(x, thresh.shape[1]))


    good_contours.append((cnts,labelMask))
    random.shuffle(good_contours)
    
    ############# PLOT #######################
  # good_contours.sort(key=lambda x:get_contour_precedence(x[0], thresh.shape[1]))

  good_contours.sort(key=lambda x:cv2.boundingRect(max(x[0], key=cv2.contourArea))[0])


  asciiLabels = []
  labelMaskList = []
  for cnts, labelMask in good_contours:
    # ensure at least one contour was found in the mask
    if len(cnts) > 0:
      # grab the largest contour which corresponds to the component in the mask, then
      # grab the bounding box for the contour

      # c = min(cnts, key=cv2.contourArea)
      c = max(cnts, key=cv2.contourArea)
      (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)
      # print('Counter: ', Counter)

      # print("Divide", boxW/float(boxH))
      # print("KeepAspect", (boxW/float(boxH)) < 1.0)
      # print("Divide", cv2.contourArea(c)/float(boxW * boxH))
      # print("Keep Solidity", (cv2.contourArea(c)/float(boxW * boxH)) > 0.15)
      # print("Divide", boxH / float(thresh.shape[0]))
      # print("Keep Height", (boxH / float(thresh.shape[0]) > 0.4) and (boxH / float(thresh.shape[0])<0.95))

      # print("\n")
      
      

      # compute the aspect ratio, solidity, and height ratio for the component
      aspectRatio = boxW / float(boxH)
      solidity = cv2.contourArea(c) / float(boxW * boxH)
      heightRatio = boxH / float(thresh.shape[0])

      # determine if the aspect ratio, solidity, and height of the contour pass
      # the rules tests
      keepAspectRatio = aspectRatio < 1.0
      keepSolidity = solidity > 0.15
      keepHeight = heightRatio > 0.55 and heightRatio < 0.95
      # keepHeight = heightRatio > 0.4 and heightRatio < 0.95  ###ORIGINAL###

      # check to see if the component passes all the tests
      if keepAspectRatio and keepSolidity and keepHeight:
        # compute the convex hull of the contour and draw it on the character
        # candidates mask
        try:
          hull = cv2.convexHull(c)
          cv2.drawContours(charCandidates, [hull], -1, 255, -1) 
        except Exception:
          print("Issue with drawcontours. This is the image:        ")
          print(image_path)
          badImages.append(image_path)
          continue
        else:
          ###print("We good")
          labelMask = labelMask[boxY:boxY+boxH, boxX:boxX+boxW]
          labelMask = cv2.copyMakeBorder(labelMask,5, 5, 5, 5, cv2.BORDER_CONSTANT, value=0)
          labelMask = cv2.resize(labelMask, (30,60))
          # plt.imshow(labelMask, cmap='gray')
          # plt.show()
          labelMaskList.append(labelMask)
          labelIndexVal = labelDict[image_path]
          labelString = plateLabels[labelIndexVal]
          if (not asciiLabels):
            for i in labelString:
              x = ord(i)
              if(x >= ord('0') and x <= ord('9')):
                temp = x-ord('0')
                asciiLabels.append(temp)
                # print(type(x-ord('0')))
                # print(x-ord('0'))
              else:
                temp = x-ord('A')+10
                asciiLabels.append(temp)
                # print(type(x-ord('A')+10))
                # print(x-ord('A')+10)
            validationLabel.append(asciiLabels) 
  if (labelMaskList):
    validationSet.append(labelMaskList)
        ############### FILTERED PLOT, BUT NOT WORKING ##########################
        # plt.imshow(labelMask, cmap='gray')
        # plt.show()  
  # print(keepAspectRatio)
  # print(keepSolidity)
  # print(keepHeight)

print(len(validationLabel))
print(validationLabel)
print(len(validationSet))

testingSet = []
testingLabel = []

maskList = []
carImage = -1
path = '/content/drive/My Drive/Colab Notebooks/APS360/Project/dataset/'
counter = 0
for image_path in testIndices:
  carImage+=1
  print("Iteration Count:   ")
  counter+=1
  print(counter)
  maskList.clear()
  print(image_path)
  input_path = os.path.join(path, image_path)
  image = cv2.imread(input_path)
  # plt.imshow(image)
  # plt.show()
  cv2.waitKey(0)
  imageName = image_path[:-4]
  # print(imageName)
  rowEntry = plateDetails.loc[plateDetails['Index'] == imageName]
  # print(rowEntry)
  ymax = int(rowEntry['Ymax'])
  ymin = int(rowEntry['Ymin'])
  xmax = int(rowEntry['Xmax'])
  xmin = int(rowEntry['Xmin'])
  # print(ymax, ymin, xmax, xmin)
  crop_img = image[ymin:ymax, xmin:xmax]
  # plt.imshow(crop_img)
  # plt.show()
  cv2.waitKey(0)
  # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  # gray2 = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
  # img_gray_mode = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

  # plt.imshow(image)
  # plt.show()
  # plt.imshow(image_rgb)
  # plt.show()
  # plt.imshow(gray)
  # plt.show()
  # plt.imshow(gray, cmap='gray')
  # plt.show()
  # for child in root.iter('xmin'):
  #   xmin = int(child.text)

  # for child in root.iter('xmax'):
  #   xmax = int(child.text)

  # for child in root.iter('ymin'):
  #   ymin = int(child.text)

  # for child in root.iter('ymax'):
  #   ymax = int(child.text)

  # print(xmin)
  # print(xmax)
  # print(ymin)
  # print(ymax)

  # crop_img = image[ymin:ymax, xmin:xmax]
  # plt.imshow(crop_img)
  # plt.show()
  # cv2.waitKey(0)

  # image = cv2.imread('/root/train/040603/P1010001.jpg')

  #image = cv2.imread('/root/train/040603/P6040015.jpg')
  #image = cv2.imread('/content/drive/My Drive/Colab Notebooks/APS360/Project/images/Cars1.png')
  # image = cv2.imread('/root/train/040603/P1010003.jpg')
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  gray2 = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
  img_gray_mode = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


  # plt.imshow(image)
  # plt.show()
  # plt.imshow(image_rgb)
  # plt.show()
  # plt.imshow(gray)
  # plt.show()
  # plt.imshow(gray, cmap='gray')
  # plt.show()
  # plt.imshow(gray2)
  # plt.show()
  # plt.imshow(img_gray_mode)
  # plt.show()
  #ksize was 3 before
  sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=1)
  sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=1)
  # plt.imshow(sobelx+sobely,cmap = 'gray')

  edged = cv2.Canny(gray, 170, 200)
  # plt.imshow(edged,cmap = 'gray')

  gray_noise = cv2.bilateralFilter(gray, 11, 17, 17)
  edged2 = cv2.Canny(gray_noise, 170, 200)
  # plt.imshow(edged2,cmap = 'gray')

  # mask = np.zeros(gray.shape,np.uint8) #Array filled with zeros, basically black box
  # image_masked = cv2.drawContours(mask,[screenCnt],0,255,-1,) #Draw found contour on mask and fill it white
  # image_masked = cv2.bitwise_and(image,image,mask=mask) #Bitwise and, to keep everything within contour

  # plt.imshow(image_masked)

  # # Now crop
  # (x, y) = np.where(mask == 255)
  # (topx, topy) = (np.min(x), np.min(y))
  # (bottomx, bottomy) = (np.max(x), np.max(y))
  # cropped_img = image[topx:bottomx+1, topy:bottomy+1]

  # plt.imshow(cropped_img)

  # # Now crop
  # (x, y) = np.where(mask == 255)
  # (topx, topy) = (np.min(x), np.min(y))
  # (bottomx, bottomy) = (np.max(x), np.max(y))
  # cropped = gray[topx:bottomx+1, topy:bottomy+1]

  # plt.imshow(cropped, cmap='gray')
  # extract the Value component from the HSV color space and apply adaptive thresholding
  # to reveal the characters on the license plate
  V = cv2.split(cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV))[2]
  # T = threshold_local(V, 29, offset=15, method="gaussian") #################ORIGINAL 29, CHANGED TO 99
  T = threshold_local(V, 99, offset=15, method="gaussian")
  thresh = (V > T).astype("uint8") * 255
  thresh = cv2.bitwise_not(thresh)

  # plt.imshow(thresh, cmap='gray')
  # plt.show()

  from skimage import measure
  import random
  good_contours = []
  labels = measure.label(thresh, neighbors=8, background=0)
  charCandidates = np.zeros(thresh.shape, dtype="uint8")
  #print(len(np.unique(labels)))

  # loop over the unique components
  for label in np.unique(labels):
    # if this is the background label, ignore it
    if label == 0:
      continue

    # otherwise, construct the label mask to display only connected components for the
    # current label, then find contours in the label mask
    labelMask = np.zeros(thresh.shape, dtype="uint8")
    labelMask[labels == label] = 255
    cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
    # (cnts, _) = contours.sort_contours(cnts, method="top-to-bottom") ####ADDED#####################
    # (cnts, _) = contours.sort_contours(cnts, method="left-to-right") ####ADDED#####################
    # cnts = cnts[0] if imutils.is_cv2() else cnts[1]

    # cnts.sort(key=lambda x:get_contour_precedence(x, thresh.shape[1]))


    good_contours.append((cnts,labelMask))
    random.shuffle(good_contours)
    
    ############# PLOT #######################
  # good_contours.sort(key=lambda x:get_contour_precedence(x[0], thresh.shape[1]))

  good_contours.sort(key=lambda x:cv2.boundingRect(max(x[0], key=cv2.contourArea))[0])

  asciiLabels = []
  labelMaskList = []
  for cnts, labelMask in good_contours:
    # ensure at least one contour was found in the mask
    if len(cnts) > 0:
      # grab the largest contour which corresponds to the component in the mask, then
      # grab the bounding box for the contour

      # c = min(cnts, key=cv2.contourArea)
      c = max(cnts, key=cv2.contourArea)
      (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)
      # print('Counter: ', counter)

      # print("Divide", boxW/float(boxH))
      # print("KeepAspect", (boxW/float(boxH)) < 1.0)
      # print("Divide", cv2.contourArea(c)/float(boxW * boxH))
      # print("Keep Solidity", (cv2.contourArea(c)/float(boxW * boxH)) > 0.15)
      # print("Divide", boxH / float(thresh.shape[0]))
      # print("Keep Height", (boxH / float(thresh.shape[0]) > 0.4) and (boxH / float(thresh.shape[0])<0.95))

      # print("\n")
      
      

      # compute the aspect ratio, solidity, and height ratio for the component
      aspectRatio = boxW / float(boxH)
      solidity = cv2.contourArea(c) / float(boxW * boxH)
      heightRatio = boxH / float(thresh.shape[0])

      # determine if the aspect ratio, solidity, and height of the contour pass
      # the rules tests
      keepAspectRatio = aspectRatio < 1.0
      keepSolidity = solidity > 0.15
      keepHeight = heightRatio > 0.55 and heightRatio < 0.95
      # keepHeight = heightRatio > 0.4 and heightRatio < 0.95  ###ORIGINAL###

      # check to see if the component passes all the tests
      if keepAspectRatio and keepSolidity and keepHeight:
        # compute the convex hull of the contour and draw it on the character
        # candidates mask
        try:
          hull = cv2.convexHull(c)
          cv2.drawContours(charCandidates, [hull], -1, 255, -1) 
        except Exception:
          print("Issue with drawcontours. This is the image:        ")
          print(image_path)
          badImages.append(image_path)
          continue
        else:
          ###print("We good")
          labelMask = labelMask[boxY:boxY+boxH, boxX:boxX+boxW]
          labelMask = cv2.copyMakeBorder(labelMask,5, 5, 5, 5, cv2.BORDER_CONSTANT, value=0)
          labelMask = cv2.resize(labelMask, (30,60))
          # plt.imshow(labelMask, cmap='gray')
          # plt.show()
          labelMaskList.append(labelMask)
          labelIndexVal = labelDict[image_path]
          labelString = plateLabels[labelIndexVal]
          if (not asciiLabels):
            for i in labelString:
              x = ord(i)
              if(x >= ord('0') and x <= ord('9')):
                temp = x-ord('0')
                asciiLabels.append(temp)
                # print(type(x-ord('0')))
                # print(x-ord('0'))
              else:
                temp = x-ord('A')+10
                asciiLabels.append(temp)
                # print(type(x-ord('A')+10))
                # print(x-ord('A')+10)
            testingLabel.append(asciiLabels) 
  if (labelMaskList):
    testingSet.append(labelMaskList)
)

print(len(testingLabel))
print(testingLabel)
print(len(testingSet))

# ! pip install pytesseract

# import pytesseract
# #Read the number plate
# text = pytesseract.image_to_string(cropped, config='--psm 11')
# print("Detected license plate Number is:",text)

# trainingSet = np.array(trainingSet)
# validationSet = np.array(validationSet)
# testingSet = np.array(testingSet)

for i in range(len(trainingSet)):
  trainingSet[i] = np.array(trainingSet[i])

for i in range(len(validationSet)):
  validationSet[i] = np.array(validationSet[i])

for i in range(len(testingSet)):
  testingSet[i] = np.array(testingSet[i])

for i in range(len(trainingSet)):
  trainingSet[i] = trainingSet[i]/255

for i in range(len(validationSet)):
  validationSet[i] = validationSet[i]/255

for i in range(len(testingSet)):
  testingSet[i] = testingSet[i]/255

  
# trainingSet = trainingSet/255 #Normalize data
# validationSet = validationSet/255
# testingSet = testingSet/255

for i in range(len(trainingLabel)):
  trainingLabel[i] = np.array(trainingLabel[i])

for i in range(len(validationLabel)):
  validationLabel[i] = np.array(validationLabel[i])

for i in range(len(testingLabel)):
  trainingLabel[i] = np.array(trainingLabel[i])
# trainingLabel = np.array(trainingLabel)
# validationLabel = np.array(validationLabel)
# testingLabel = np.array(testingLabel)

print(type(trainingSet[0][1]))

trainData = []
validData = []
testData = []

# for i in range(trainingLabel.shape[0]):
#   trainData.append([trainingSet[i],trainingLabel[i]])

# for i in range(validationLabel.shape[0]):
#   validData.append([validationSet[i],validationLabel[i]])

# for i in range(testingLabel.shape[0]):
#   testData.append([testingSet[i],testingLabel[i]])

count = 0
for i in range(len(trainingLabel)):
  for j in range(len(trainingSet[i])):
    try:
      trainData.append([trainingSet[i][j], trainingLabel[i][j]])
    except Exception:
      count+=1
      continue

print(count)

count = 0
for i in range(len(validationLabel)):
  for j in range(len(validationSet[i])):
    try:
      validData.append([validationSet[i][j], validationLabel[i][j]])
    except Exception:
      count+=1
      continue

print(count)

count = 0
for i in range(len(testingLabel)):
  for j in range(len(testingSet[i])):
    try:
      testData.append([testingSet[i][j], testingLabel[i][j]])
    except Exception:
      count+=1
      continue

print(count)

print(type(validData[0][1]))

print(len(trainingSet))

import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
class ANN(nn.Module):
    def __init__(self):
        super(ANN, self).__init__()
        self.fc1 = nn.Linear(30*60, 1000)
        self.fc2 = nn.Linear(1000,36)
        
    def forward(self, x):
        flattened = x.view(-1, 30*60)
        activation1 = self.fc1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.fc2(activation1)
        return activation2 #Softmax is applied here interally since we use CE as a criterion.

#For loss function I used cross entropy/log loss and for optimizer
#I used SGD. Log loss is one of the best loss functions for classification problems.
#I chose SGD since it is one of the best optimizers.
def get_accuracy(model,data_loader):

    correct = 0
    total = 0
    for imgs, labels in data_loader:
        
        #imgs = alexNet.features(imgs) #SLOW
        #############################################
        #To Enable GPU Usage
        if torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = torch.tensor(labels)
          labels = labels.cuda()
        #############################################
        
        
        output = model(imgs)
        
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def train(model,batch_size=20, num_epochs=1,learningRate = 0.005,data = None,validData = None):

  train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, 
                                           num_workers=1, shuffle=True)
  valid_loader = torch.utils.data.DataLoader(validData, batch_size=batch_size, 
                                           num_workers=1, shuffle=True)
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(model.parameters(), lr=learningRate, momentum=0.9)
  
  iters, losses, train_acc, val_acc = [], [], [], []
  listOfEpochs = []
  validIters,validLoss = [],[]
  # training
  n = 0 # the number of iterations
  nValid = 0
  for epoch in range(num_epochs):
      
      listOfEpochs.append(epoch)
      train_acc.append(get_accuracy(model, train_loader))
      val_acc.append(get_accuracy(model,valid_loader))
      for imgs, labels in iter(valid_loader):
         if torch.cuda.is_available():
            imgs = imgs.cuda()
            labels = torch.tensor(labels)
            labels = labels.cuda()
            out = model(imgs) 
            loss = criterion(out, labels) # compute the total loss
            validIters.append(nValid)
            validLoss.append(loss)
            nValid += 1


      for imgs, labels in iter(train_loader):
          #imgs = features = alexNet.features(imgs) #SLOW
            #############################################
            #To Enable GPU Usage
          
          if torch.cuda.is_available():
            imgs = imgs.cuda()
            labels = torch.tensor(labels)
            labels = labels.cuda()
            #############################################
            
              
          out = model(imgs)             # forward pass
        
        
          loss = criterion(out, labels) # compute the total loss
          loss.backward()               # backward pass (compute parameter updates)
          optimizer.step()              # make the updates for each parameter
          optimizer.zero_grad()         # a clean up step for PyTorch

          # save the current training information
          iters.append(n)
          losses.append(float(loss)/batch_size)             # compute *average* loss
          #train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy 
          #val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy
          n += 1

  print("Training accuracy = "+str(get_accuracy(model,train_loader)))
  print("Validation accuracy = "+str(get_accuracy(model,valid_loader)))


  plt.title("Training Loss")
  plt.plot(iters, losses, label="Train")
  plt.xlabel("Iterations")
  plt.ylabel("Loss")
  plt.show()

  plt.title("Validation Loss")
  plt.plot(validIters, validLoss, label="Valid")
  plt.xlabel("Iterations")
  plt.ylabel("Loss")
  plt.show()

  plt.plot(listOfEpochs, train_acc, label="Train")
  plt.xlabel("Epochs")
  plt.ylabel("Accuracy")
  plt.plot(listOfEpochs, val_acc, label="Train")
  plt.xlabel("Epochs")
  plt.ylabel("Accuracy")
  plt.legend(['Training Accuracy','Validation Accuracy'])
  plt.title('Training and Validation Accuracies')
  plt.show()

myNet = ANN()
myNet = myNet.cuda()
train(myNet.double(),64,50,0.005,trainData,validData)

test_loader = torch.utils.data.DataLoader(testData, batch_size=1, 
                                           num_workers=1, shuffle=False)

imgCounter = 0
correct = 0
testPlateLabels = []
s = ''
testSet = [0, 2, 3, 4, 6, 7, 8, 9, 15, 16, 19, 20, 21, 24, 26]
#Change character to strings of license plates
for imgs, labels in iter(test_loader):
        
           
        if torch.cuda.is_available():
            imgs = imgs.cuda()
            labels = labels.cuda()
        #out = bmyNet(imgs)
        out = myNet(imgs)
        pred = out.max(1, keepdim=True)[1]
        imgCounter = imgCounter + 1
        if (pred >= 0 and pred <= 9):
          predChar = chr(pred+ord('0'))
        else:
          predChar = chr(pred+ord('A')-10)
        s = s+predChar
        imgCounter = 0
        testPlateLabels.append(s)
        s = ''

targetLabels = []

for i in range(len(testIndices)):
  temp = testIndices[i]
  temp2 = labelDict[temp]
  targetLabels.append(plateLabels[temp2])

#print(targetLabels)
plateLengths = []

for i in targetLabels:
  plateLengths.append(len(i))

lengthIndex = 0
testPlateLabelsStrings = []
counter = 0
fullString = ''
for i in range(len(testPlateLabels)):
  counter+=1
  temp = plateLengths[lengthIndex]
  temp = temp-counter
  fullString += testPlateLabels[i]
  if temp == 0:
    testPlateLabelsStrings.append(fullString)
    lengthIndex+=1
    fullString = ''
    counter = 0

# print(testPlateLabels)
#print(testPlateLabelsStrings)
total = len(testPlateLabelsStrings)
correctPlates = 0
#[0, 2, 3, 4, 6, 7, 8, 9, 15, 16, 19, 20, 21, 24, 26]

for i in range(len(testPlateLabelsStrings)):
  image = cv2.imread(path)
  print(testPlateLabelsStrings[i])
  if(testPlateLabelsStrings[i] == targetLabels[i]):
    correctPlates = correctPlates+1

# print(correctPlates)
# print(total)
# print('Accuracy of plate recognition: '+str(correctPlates/total))

